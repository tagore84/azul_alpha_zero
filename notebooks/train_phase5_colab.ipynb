{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Azul Zero Training - Phase 5.0 GPU-Optimized (Google Colab)\n",
                "\n",
                "This notebook is **optimized for Google Colab T4 GPU**:\n",
                "- **Reduced games** to minimize CPU-bound self-play\n",
                "- **Increased epochs** to maximize GPU utilization during training\n",
                "- **Larger batch size** (128/256) to saturate GPU memory\n",
                "- **Buffer Size:** 150,000 examples (reduced for faster training cycles)\n",
                "\n",
                "## GPU-Optimized Curriculum\n",
                "- **Warmup (Cycles 1-5):** 100 sims, 100 games, 20 epochs, batch=128\n",
                "- **Scaling (Cycles 6-20):** 200 sims, 250 games, 20 epochs, batch=128\n",
                "- **High Quality (Cycles 21+):** 400 sims, 500 games, 20 epochs, batch=256\n",
                "\n",
                "## Setup Instructions\n",
                "1. Upload your `azul_zero` project folder to Google Drive\n",
                "2. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\n",
                "3. Run all cells in order"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Navigate to project directory (adjust path as needed)\n",
                "import os\n",
                "PROJECT_PATH = '/content/drive/MyDrive/azul_zero'  # CHANGE THIS to your project path\n",
                "os.chdir(PROJECT_PATH)\n",
                "print(f\"Working directory: {os.getcwd()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q torch numpy gym"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "import torch\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è WARNING: GPU not detected. Training will be VERY slow.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training parameters (GPU-optimized)\n",
                "TOTAL_CYCLES = 50\n",
                "MAX_DATASET_SIZE = 150000  # Reduced for faster cycles\n",
                "CHECKPOINT_DIR = 'data/checkpoints_v5_gpu'\n",
                "RESUME = True  # Set to False to start from scratch"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import torch\n",
                "import time\n",
                "from datetime import datetime\n",
                "\n",
                "# Add project src folder to PYTHONPATH\n",
                "sys.path.insert(0, os.path.abspath('src'))\n",
                "\n",
                "from azul.env import AzulEnv\n",
                "from net.azul_net import AzulNet\n",
                "from train.self_play import generate_self_play_games\n",
                "from train.dataset import AzulDataset\n",
                "from train.trainer import Trainer\n",
                "from players.heuristic_player import HeuristicPlayer\n",
                "from players.random_player import RandomPlayer\n",
                "from players.random_plus_player import RandomPlusPlayer\n",
                "from mcts.mcts import MCTS\n",
                "import copy\n",
                "\n",
                "class TrainingLogger:\n",
                "    def __init__(self, log_dir):\n",
                "        self.log_dir = log_dir\n",
                "        os.makedirs(log_dir, exist_ok=True)\n",
                "        self.log_file = os.path.join(log_dir, \"training.log\")\n",
                "        self.buffer = []\n",
                "        \n",
                "        with open(self.log_file, \"a\") as f:\n",
                "            f.write(f\"\\n{'='*20}\\n[{datetime.now()}] Colab GPU Training Started\\n{'='*20}\\n\")\n",
                "\n",
                "    def log(self, msg):\n",
                "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
                "        formatted_msg = f\"[{timestamp}] {msg}\"\n",
                "        print(formatted_msg)\n",
                "        self.buffer.append(formatted_msg)\n",
                "        \n",
                "        with open(self.log_file, \"a\") as f:\n",
                "            f.write(formatted_msg + \"\\n\")\n",
                "\n",
                "def get_curriculum_params(cycle):\n",
                "    \"\"\"GPU-optimized curriculum: fewer games, more epochs, larger batches\"\"\"\n",
                "    params = {\n",
                "        'n_games': 250,\n",
                "        'simulations': 200,\n",
                "        'epochs': 20,\n",
                "        'batch_size': 128,\n",
                "        'lr': 1e-3,\n",
                "        'cpuct': 1.2,\n",
                "        'temp_threshold': 0,\n",
                "        'noise_alpha': 0.3,\n",
                "        'noise_eps': 0.25\n",
                "    }\n",
                "    \n",
                "    if cycle <= 5:\n",
                "        # Warmup: Fast cycles for initial learning\n",
                "        params['n_games'] = 100\n",
                "        params['simulations'] = 100\n",
                "        params['epochs'] = 20\n",
                "        params['batch_size'] = 128\n",
                "        params['lr'] = 1e-3\n",
                "        params['cpuct'] = 1.0\n",
                "    elif cycle <= 20:\n",
                "        # Scaling: Balanced self-play and training\n",
                "        params['n_games'] = 250\n",
                "        params['simulations'] = 200\n",
                "        params['epochs'] = 20\n",
                "        params['batch_size'] = 128\n",
                "        params['lr'] = 5e-4\n",
                "        params['cpuct'] = 1.2\n",
                "    else:\n",
                "        # High Quality: Maximum quality search\n",
                "        params['n_games'] = 500\n",
                "        params['simulations'] = 400\n",
                "        params['epochs'] = 20\n",
                "        params['batch_size'] = 256  # Use more VRAM\n",
                "        params['lr'] = 1e-4\n",
                "        params['cpuct'] = 1.5\n",
                "        \n",
                "    return params\n",
                "\n",
                "print(\"‚úÖ Training functions loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize training\n",
                "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
                "logger = TrainingLogger(\"logs_v5_gpu\")\n",
                "\n",
                "# Setup device\n",
                "if torch.cuda.is_available():\n",
                "    device = torch.device('cuda')\n",
                "elif torch.backends.mps.is_available():\n",
                "    device = torch.device('mps')\n",
                "else:\n",
                "    device = torch.device('cpu')\n",
                "logger.log(f\"Using device: {device}\")\n",
                "\n",
                "# Initialize Environment\n",
                "env = AzulEnv(num_players=2)\n",
                "obs_flat = env.encode_observation(env.reset())\n",
                "total_obs_size = obs_flat.shape[0]\n",
                "in_channels = env.num_players * 2\n",
                "spatial_size = in_channels * 5 * 5\n",
                "factories_size = (env.N + 1) * 5\n",
                "global_size = total_obs_size - spatial_size - factories_size\n",
                "action_size = env.action_size\n",
                "\n",
                "logger.log(f\"Obs shape: Total={total_obs_size}, Global={global_size}\")\n",
                "\n",
                "# Initialize Model\n",
                "model = AzulNet(\n",
                "    in_channels=in_channels,\n",
                "    global_size=global_size,\n",
                "    action_size=action_size,\n",
                "    factories_count=env.N\n",
                ").to(device)\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
                "\n",
                "# Log model size\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "logger.log(f\"Model parameters: {total_params:,}\")\n",
                "\n",
                "replay_buffer = []\n",
                "start_cycle = 1\n",
                "\n",
                "# Resume from checkpoint if requested\n",
                "if RESUME:\n",
                "    checkpoints = [f for f in os.listdir(CHECKPOINT_DIR) if f.startswith('model_cycle_') and f.endswith('.pt')]\n",
                "    if checkpoints:\n",
                "        cycles = [int(f.replace('model_cycle_', '').replace('.pt', '')) for f in checkpoints]\n",
                "        last_cycle = max(cycles)\n",
                "        ckpt_path = os.path.join(CHECKPOINT_DIR, f\"model_cycle_{last_cycle}.pt\")\n",
                "        logger.log(f\"Loading checkpoint: {ckpt_path}\")\n",
                "        checkpoint = torch.load(ckpt_path, map_location=device)\n",
                "        model.load_state_dict(checkpoint['model_state'])\n",
                "        optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
                "        start_cycle = last_cycle + 1\n",
                "        logger.log(f\"Resumed from cycle {last_cycle}\")\n",
                "\n",
                "logger.log(f\"Starting from cycle {start_cycle}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Main Training Loop (GPU-Optimized)\n",
                "for cycle in range(start_cycle, TOTAL_CYCLES + 1):\n",
                "    cycle_start = time.time()\n",
                "    params = get_curriculum_params(cycle)\n",
                "    logger.log(f\"\\n{'='*60}\")\n",
                "    logger.log(f\"CYCLE {cycle}/{TOTAL_CYCLES}\")\n",
                "    logger.log(f\"Games: {params['n_games']}, Sims: {params['simulations']}, \"\n",
                "               f\"Epochs: {params['epochs']}, Batch: {params['batch_size']}\")\n",
                "    logger.log(f\"{'='*60}\")\n",
                "    \n",
                "    # 1. Self-Play (CPU-bound, sequential on GPU)\n",
                "    selfplay_start = time.time()\n",
                "    logger.log(f\"[Self-Play] Generating {params['n_games']} games...\")\n",
                "    model.eval()\n",
                "    new_examples, mcts_stats = generate_self_play_games(\n",
                "        verbose=False,\n",
                "        n_games=params['n_games'],\n",
                "        env=env,\n",
                "        model=model,\n",
                "        simulations=params['simulations'],\n",
                "        cpuct=params['cpuct'],\n",
                "        temperature_threshold=params['temp_threshold'],\n",
                "        noise_alpha=params['noise_alpha'],\n",
                "        noise_epsilon=params['noise_eps']\n",
                "    )\n",
                "    selfplay_time = time.time() - selfplay_start\n",
                "    \n",
                "    logger.log(f\"[Self-Play] Time: {selfplay_time/60:.1f} min\")\n",
                "    logger.log(f\"[Self-Play] MCTS stats: visits={mcts_stats['avg_visits']:.1f}, \"\n",
                "               f\"entropy={mcts_stats['avg_entropy']:.2f}, \"\n",
                "               f\"reuse={mcts_stats['avg_reuse_rate']:.1%}\")\n",
                "    \n",
                "    # 2. Update Buffer\n",
                "    if new_examples:\n",
                "        replay_buffer.extend(new_examples)\n",
                "        if len(replay_buffer) > MAX_DATASET_SIZE:\n",
                "            replay_buffer = replay_buffer[-MAX_DATASET_SIZE:]\n",
                "        logger.log(f\"[Buffer] Size: {len(replay_buffer):,} examples\")\n",
                "    else:\n",
                "        logger.log(\"[Buffer] WARNING: No new examples generated!\")\n",
                "    \n",
                "    # 3. Training (GPU-bound, should be fast)\n",
                "    train_start = time.time()\n",
                "    logger.log(f\"[Training] Starting {params['epochs']} epochs with batch_size={params['batch_size']}...\")\n",
                "    dataset = AzulDataset(replay_buffer, augment_factories=True)\n",
                "    dataloader = torch.utils.data.DataLoader(\n",
                "        dataset, \n",
                "        batch_size=params['batch_size'],  # GPU-optimized batch size\n",
                "        shuffle=True,\n",
                "        num_workers=2,  # Parallel data loading\n",
                "        pin_memory=True if device.type == 'cuda' else False\n",
                "    )\n",
                "    \n",
                "    for param_group in optimizer.param_groups:\n",
                "        param_group['lr'] = params['lr']\n",
                "    \n",
                "    trainer = Trainer(model, optimizer, device, log_dir=f'logs_v5_gpu/cycle_{cycle}')\n",
                "    history = trainer.fit(dataloader, epochs=params['epochs'])\n",
                "    train_time = time.time() - train_start\n",
                "    \n",
                "    avg_loss = sum(history['train_loss']) / len(history['train_loss']) if history['train_loss'] else 0\n",
                "    avg_policy = sum(history['train_loss_policy']) / len(history['train_loss_policy']) if history['train_loss_policy'] else 0\n",
                "    avg_value = sum(history['train_loss_value']) / len(history['train_loss_value']) if history['train_loss_value'] else 0\n",
                "    logger.log(f\"[Training] Time: {train_time/60:.1f} min\")\n",
                "    logger.log(f\"[Training] Loss: {avg_loss:.4f} (Policy: {avg_policy:.4f}, Value: {avg_value:.4f})\")\n",
                "    \n",
                "    # 4. Save Checkpoint\n",
                "    ckpt_path = os.path.join(CHECKPOINT_DIR, f\"model_cycle_{cycle}.pt\")\n",
                "    torch.save({\n",
                "        'cycle': cycle,\n",
                "        'model_state': model.state_dict(),\n",
                "        'optimizer_state': optimizer.state_dict(),\n",
                "        'params': params,\n",
                "        'buffer_size': len(replay_buffer)\n",
                "    }, ckpt_path)\n",
                "    logger.log(f\"[Checkpoint] Saved: {ckpt_path}\")\n",
                "    \n",
                "    # Save best model\n",
                "    torch.save({'model_state': model.state_dict()}, \n",
                "               os.path.join(CHECKPOINT_DIR, \"best.pt\"))\n",
                "    \n",
                "    # Cycle summary\n",
                "    cycle_time = time.time() - cycle_start\n",
                "    logger.log(f\"\\n[Summary] Cycle {cycle} completed in {cycle_time/60:.1f} min\")\n",
                "    logger.log(f\"[Summary] Self-Play: {selfplay_time/cycle_time*100:.1f}%, Training: {train_time/cycle_time*100:.1f}%\")\n",
                "    \n",
                "    # Clear GPU cache\n",
                "    if device.type == 'cuda':\n",
                "        torch.cuda.empty_cache()\n",
                "\n",
                "logger.log(\"\\nüéâ Training Complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Performance Analysis\n",
                "\n",
                "Run this cell to see GPU utilization during training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU memory usage\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
                "    print(f\"GPU Memory Reserved: {torch.cuda.memory_reserved()/1e9:.2f} GB\")\n",
                "    print(f\"GPU Max Memory: {torch.cuda.max_memory_allocated()/1e9:.2f} GB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Download Checkpoints (Optional)\n",
                "\n",
                "Run this cell to download the final checkpoint to your local machine."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "\n",
                "# Download best model\n",
                "files.download(os.path.join(CHECKPOINT_DIR, 'best.pt'))\n",
                "\n",
                "# Or download specific cycle (change cycle number)\n",
                "# files.download(os.path.join(CHECKPOINT_DIR, 'model_cycle_50.pt'))"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}